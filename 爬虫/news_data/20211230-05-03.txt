强化人工智能安全治理（新论）　　作为新一轮科技革命和产业变革的重要驱动力量，人工智能技术发展与应用拓展正在按下“快进键”。今年11月，习近平总书记主持召开的中央政治局会议强调，加快提升生物安全、网络安全、数据安全、人工智能安全等领域的治理能力。这为推动人工智能健康发展提供了重要指引。　　在人机协同、跨界融合、共创分享的智能时代，人工智能的应用场景愈发广泛。人工智能为经济社会发展注入活力的同时，也给人类生活带来了新的风险挑战，比如对个人隐私权、知情权、选择权的侵犯，以及窃取、篡改、泄露等非法收集利用个人信息的行为，等等。为此，迫切需要加快提升人工智能安全治理能力，加强人工智能相关法律、伦理、社会问题等研究，建立健全保障人工智能健康发展的法律法规与伦理体系。　　加快提升人工智能安全治理能力，需要完善相关的法律法规及行业标准。人工智能的安全秩序包含算法安全、数据安全、伦理安全、国家安全等维度。2019年以来，中国先后发布《新一代人工智能治理原则——发展负责任的人工智能》《全球数据安全倡议》等文件，明确了人工智能治理框架和行动指南。今年9月发布的《新一代人工智能伦理规范》强调，将伦理道德融入人工智能全生命周期，促进公平、公正、和谐、安全，避免偏见、歧视、隐私和信息泄露等问题，为从事人工智能相关活动的自然人、法人和其他相关机构等提供了伦理指引。　　加快提升人工智能安全治理能力，要引导社会公众正确认识人工智能。人工智能监管者要提高站位，加强宏观战略研究与风险防范；人工智能研发者要坚持正确价值导向，避免可能存在的数据与算法偏见，努力实现人工智能系统的普惠性、公平性和非歧视性；人工智能的技术提供者要明确告知义务，加强应急保障；人工智能产品的使用者，应当保证这一技术不被误用、滥用或恶用。要对各类伦理道德风险保持高度警惕，坚持以人为本，落实科技向善理念，弘扬社会主义核心价值观。　　加强人工智能发展的潜在风险研判和防范，确保人工智能安全、可靠、可控，也是摆在世界各国面前的重要课题。在推动完善人工智能全球治理方面，中国是积极倡导者，也是率先践行者。2020年9月，中国发布《全球数据安全倡议》，明确提出秉持共商共建共享理念，齐心协力促进数据安全；今年5月，中国担任联合国安理会轮值主席期间，主持召开“新兴科技对国际和平与安全的影响”阿里亚模式会议，推动安理会首次聚焦人工智能等新兴科技问题，为国际社会探讨新兴科技全球治理问题提供了重要平台，体现了大国责任担当。　　数字化浪潮扑面而来，信息化、数字化、智能化趋势不断演进。主动加强对人工智能的伦理与法律规范，才能更好适应人工智能快速发展的新变化、新要求，在法治轨道上推动人工智能向善发展、造福人类。　　（作者为北京理工大学法学院教授）